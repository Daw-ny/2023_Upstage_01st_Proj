{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3b4643",
   "metadata": {},
   "source": [
    "# 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e3909",
   "metadata": {},
   "source": [
    "### (1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4f2d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.14.0\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "print(selenium.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b3539",
   "metadata": {},
   "source": [
    "### (2) 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ead600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import html5lib\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271d8d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "ChromeDriverManager().install()\n",
    "browser = webdriver.Chrome() # 우리가 컨트롤 할 수 있는 브라우저가 실행이된다.\n",
    "\n",
    "# selenium -> chromedriver -> chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f47506fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NAVER'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.get('https://www.naver.com')\n",
    "browser.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c88592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "browser.find_element(By.ID, 'query').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c650160",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element(By.ID, 'query').send_keys(\"날씨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8c5b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element(By.ID, 'search-btn').click() # 검색 아이콘 클릭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69388726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19.2°'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = browser.find_element(By.CLASS_NAME, 'temperature_text').text\n",
    "word.split(\"\\n\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bfefdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"5cb1335248bbe926211897c0b340f96e\", element=\"A8814798A064E8E75F32A6EA2691C39F_element_97\")>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.find_element(By.CLASS_NAME, 'temperature_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08585215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'°'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.find_element(By.CLASS_NAME, 'temperature_text').find_element(By.CLASS_NAME, 'celsius').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d74a7f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('20.2°', '69%', '1.2m/s')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체감, 습도, 풍향 각각의 변수로 저장해봅시다.\n",
    "data = browser.find_element(By.CLASS_NAME, 'summary_list').text\n",
    "data.split(\" \")\n",
    "\n",
    "temp = data.split(\" \")[1]\n",
    "hum = data.split(\" \")[3]\n",
    "wind = data.split(\" \")[5]\n",
    "temp, hum, wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fdff362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"5cb1335248bbe926211897c0b340f96e\", element=\"A8814798A064E8E75F32A6EA2691C39F_element_99\")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.find_element(By.CLASS_NAME, 'summary_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2507c2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20.2°'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.find_element(By.CLASS_NAME, 'summary_list').find_element(By.TAG_NAME, 'dd').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47d8848e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.2°\n",
      "69%\n",
      "1.2m/s\n"
     ]
    }
   ],
   "source": [
    "weather_list = browser.find_element(By.CLASS_NAME, 'summary_list').find_elements(By.TAG_NAME, 'dd')\n",
    "\n",
    "for i in weather_list:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3d5f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환율 페이지로 이동\n",
    "url = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=nexearch&query=%ED%99%98%EC%9C%A8&oquery=%EB%82%A0%EC%94%A8&tqi=if%2BkOdprvOssslYQTuwssssssJw-426956'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "187ae835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.30%'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.find_element(By.CLASS_NAME, 'spt_con').find_elements(By.TAG_NAME, 'em')[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08f9c55a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 환율 페이지로 이동\u001b[39;00m\n\u001b[0;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://search.naver.com/search.naver?sm=tab_hty.top&where=nexearch&query=\u001b[39m\u001b[38;5;132;01m%E\u001b[39;00m\u001b[38;5;124mD\u001b[39m\u001b[38;5;132;01m%99%\u001b[39;00m\u001b[38;5;124m98\u001b[39m\u001b[38;5;132;01m%E\u001b[39;00m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m9C\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mA8&oquery=\u001b[39m\u001b[38;5;132;01m%E\u001b[39;00m\u001b[38;5;124mB\u001b[39m\u001b[38;5;132;01m%82%\u001b[39;00m\u001b[38;5;124mA0\u001b[39m\u001b[38;5;132;01m%E\u001b[39;00m\u001b[38;5;124mC\u001b[39m\u001b[38;5;132;01m%94%\u001b[39;00m\u001b[38;5;124mA8&tqi=if\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2BkOdprvOssslYQTuwssssssJw-426956\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m tables \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ss\\lib\\site-packages\\pandas\\io\\html.py:1212\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend)\u001b[0m\n\u001b[0;32m   1208\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m   1210\u001b[0m io \u001b[38;5;241m=\u001b[39m stringify_path(io)\n\u001b[1;32m-> 1212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ss\\lib\\site-packages\\pandas\\io\\html.py:1001\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1000\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m retained \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m-> 1001\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retained\n\u001b[0;32m   1003\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ss\\lib\\site-packages\\pandas\\io\\html.py:981\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[0;32m    978\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 981\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ss\\lib\\site-packages\\pandas\\io\\html.py:257\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 257\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ss\\lib\\site-packages\\pandas\\io\\html.py:613\u001b[0m, in \u001b[0;36m_BeautifulSoupHtml5LibFrameParser._parse_tables\u001b[1;34m(self, doc, match, attrs)\u001b[0m\n\u001b[0;32m    610\u001b[0m tables \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mfind_all(element_name, attrs\u001b[38;5;241m=\u001b[39mattrs)\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tables:\n\u001b[1;32m--> 613\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo tables found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    615\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    616\u001b[0m unique_tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "# 환율 페이지로 이동\n",
    "url = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=nexearch&query=%ED%99%98%EC%9C%A8&oquery=%EB%82%A0%EC%94%A8&tqi=if%2BkOdprvOssslYQTuwssssssJw-426956'\n",
    "\n",
    "tables = pd.read_html(url)\n",
    "#currency_df = tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ae288",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fd5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 절대경로와 상대경로에 대한 이해가 필요합니다.\n",
    "currency_df.to_csv('currency.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fc22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 증권 표 데이터 가져오기\n",
    "url = 'https://finance.naver.com/'\n",
    "\n",
    "table_list = pd.read_html(url, encoding='euc-kr')\n",
    "len(table_list)\n",
    "\n",
    "df = table_list[0]\n",
    "df.to_csv('stock_info.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a15a38f",
   "metadata": {},
   "source": [
    "### 구글 뉴스 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c931370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 import\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e483168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 브라우저를 연다.\n",
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7023d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글 뉴스로 이동한다.\n",
    "url = 'https://www.google.com/search?q=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5+%EC%84%9C%EB%B9%84%EC%8A%A4&newwindow=1&sca_esv=574621129&biw=864&bih=1000&tbm=nws&sxsrf=AM9HkKmDg9LQk4Ij_gnx23BROXfIxck8ig%3A1697681021147&ei=fY4wZYLHCMCo2roPt4GigAE&ved=0ahUKEwjC-dPRgoGCAxVAlFYBHbeACBAQ4dUDCA0&uact=5&oq=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5+%EC%84%9C%EB%B9%84%EC%8A%A4&gs_lp=Egxnd3Mtd2l6LW5ld3MiFuyduOqzteyngOuKpSDshJzruYTsiqQyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAESLAjUP4IWPEicAp4AJABBpgBjgKgAcMgqgEGMC4xNi43uAEDyAEA-AEBqAIAwgILEAAYgAQYsQMYgwHCAgQQABgDwgIIEAAYgAQYsQOIBgE&sclient=gws-wiz-news'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95468045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최상위 기사 1개의 (1) 제목 (2) 내용 (3) 언론사 (4) 링크\n",
    "title = browser.find_element(By.CLASS_NAME, 'n0jPhd').text\n",
    "content = browser.find_element(By.CLASS_NAME, 'GI74Re').text\n",
    "company = browser.find_element(By.CLASS_NAME, 'MgUUmf').text\n",
    "link = browser.find_element(By.CLASS_NAME, 'WlydOe').get_attribute('href')\n",
    "\n",
    "title, content, company, link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글 뉴스 1페이지의 기사를 전부 가져와 봅시다.\n",
    "# 1 페이지의 기사 제목 전부를 가져와 봅시다.\n",
    "\n",
    "title_list = browser.find_elements(By.CLASS_NAME, 'n0jPhd')\n",
    "for elem in title_list:\n",
    "    print(elem.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4adce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = ['element1', 'element2', 'element3']\n",
    "\n",
    "for elem in data_list:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13342261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내용, 언론사, 링크\n",
    "    # 한달동안 같은 이슈(레벨3)에 시달린겁니다.    \n",
    "    # (1) 아 나 개발자 안되려나보다... 못해먹겠다. -> 사요나라... 다른 직무로 전환\n",
    "    # (2) 견뎌냈을 때 실력이 늘어나는데.. 맵집이 커집니다. \n",
    "    # 레벨 3밑으로 이슈가 생겨도 무덤덤하게 해결합니다.    \n",
    "    \n",
    "# 비전공자 -> 전공자의 4년을 따라잡아야 합니다. (시간은 밀도) 1년만에도 잡을 수 있겠죠.\n",
    "# 안녕하세요. 저 서울대 컴공입니다. -> 오케이. 들어오시죠.\n",
    "# 안녕하세요. 저 서울대 컴공입니다. -> 아 그래요? 어떤거 하실 줄 아시죠? 모델링 하실줄 아시나요? \n",
    "# 앱 개발 하실 줄 아시나요? -> (포트폴리오)\n",
    "# 전공자 취업 잘 한친구들 -> 앱 동아리, 학회 -> 열심히 개발한 친구들이 회사 잘 가죠.\n",
    "# 실무 역량이 쌓여있으니까.\n",
    "    \n",
    "# 1페이지\n",
    "# 2페이지\n",
    "# 3페이지..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb14c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컨테이너 박스들을 가져와서, 그 컨테이너 안에서 데이터를 가져오는 방법으로 크롤링 해보겠습니다.\n",
    "# (1) 컨테이너 박스들을 가져옵니다.\n",
    "\n",
    "containers = browser.find_elements(By.CLASS_NAME, 'SoaBEf')\n",
    "\n",
    "data_list = []\n",
    "for container in containers:\n",
    "    title = container.find_element(By.CLASS_NAME, 'n0jPhd').text    \n",
    "    content = container.find_element(By.CLASS_NAME, 'GI74Re').text\n",
    "    company = container.find_element(By.CLASS_NAME, 'MgUUmf').text\n",
    "    link = container.find_element(By.CLASS_NAME, 'WlydOe').get_attribute('href')\n",
    "    \n",
    "    # json -> 기계랑 기계는 어떻게 대화할까요?\n",
    "    # 제가 스마트폰으로 저희 집 조명을 조절할 수 있습니다.\n",
    "    # 스마트폰 -> 조명으로 소통을 해야겠죠. 소통방식 (프로토콜 -> json)\n",
    "    \n",
    "    data = {\n",
    "        \"title\" : title,\n",
    "        \"content\" : content,\n",
    "        \"company\" : company,\n",
    "        \"link\" : link        \n",
    "    }\n",
    "\n",
    "    data_list.append(data)\n",
    "\n",
    "# data_list는 리스트 data는 딕셔너리이고 리스트 안에 딕셔너리로 넣은 것 맞나요???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c7cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data_list) # df = excel\n",
    "\n",
    "df.to_csv(\"google_news.csv\", encoding='utf-8') # cp949, euc-kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 페이지를 3페이지까지 크롤링하는 코드 작성해보시죠.\n",
    "# 키워드도 바꾸고 싶어. 맨날 링크를 변경해야해? \n",
    "# 유저 한테 키워드 입력받아서 해당 키워드 데이터 가져오는 것을 만들어봅시다.\n",
    "\n",
    "# 기획으로 풀어 나가야 합니다.\n",
    "\n",
    "# (1) 검색어 (키워드)\n",
    "keyword = input('수집하시고자 하는 키워드를 알려주세요 :)')\n",
    "\n",
    "url = 'https://www.google.com/start={}'\n",
    "final_url = url.format(keyword)\n",
    "browser.get(final_url)\n",
    "\n",
    "# (2) 페이지 1페이지 ~ 5페이지까지 수집을 하고싶어.\n",
    "page = int(input(\"몇 페이지까지 크롤링할까요?\"))\n",
    "\n",
    "url = 'https://www.google.com/start={}'\n",
    "for i in range(0, 10*page, 10):\n",
    "    final_url = url.format(i)\n",
    "    print(final_url)\n",
    "    browser.get(final_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e26480",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = browser.find_element(By.CLASS_NAME, 'AaVjTc').find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "import time\n",
    "page_list = []\n",
    "for i in link_list:\n",
    "    page_link = i.get_attribute('href')\n",
    "\n",
    "    page_list.append(page_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10741490",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in page_list:\n",
    "    browser.get(link)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2daf28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감사합니다, 이따 궁금한 거 문의드릴께요. \n",
    "# 여러 창을 띄워놓고 창크기를 늘렸다 줄였다 하는 건 어떤 단축키를 쓰시나요?\n",
    "# Window키 + 화살표 왼쪽/오른쪽, 위로 (전체화면)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef700af8",
   "metadata": {},
   "source": [
    "### DB PIA 논문 데이터 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e49d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda9209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = input(\"검색하시고자 하는 논문의 제목 또는 주제를 입력하세요 : \")\n",
    "url = 'https://www.dbpia.co.kr/search/topSearch?searchOption=all&query={}'\n",
    "final_url = url.format(keyword)\n",
    "browser.get(final_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1페이지 논문 데이터를 가져와 봅시다.\n",
    "# (1) 논문 제목 (2) 저자 (3) 이용수 (4) 링크\n",
    "\n",
    "# 2페이지까지도 시도해보기 -> URL:X, 버튼을 클릭하게 만들거나.. (XPATH)\n",
    "\n",
    "# 엑셀저장까지 :)\n",
    "\n",
    "# 안녕하세요, 블로그가 너무 좋네요. 방문했습니다. 제 블로그에도 놀러오세요 ^^ -> 자동화 봇!\n",
    "# 인스타로 확장할 수도 있고... 그죠!?..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f3fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = browser.find_elements(By.CLASS_NAME, 'thesis')\n",
    "\n",
    "for data in datas:\n",
    "    title = data.find_element(By.CLASS_NAME, 'thesis__tit').text\n",
    "    author = data.find_element(By.CLASS_NAME, 'thesis__item').text\n",
    "    count = data.find_element(By.CLASS_NAME, 'thesis__useCount').text[4:]\n",
    "    link = data.find_element(By.CLASS_NAME, 'thesis__link').get_attribute('href')\n",
    "    \n",
    "    print(title, author, count, link)\n",
    "    \n",
    "# (1) 3페이지까지 가져오는 것 (XPATH 값)\n",
    "# 1p, //*[@id=\"pageList\"]/a[1]\n",
    "# 2p, //*[@id=\"pageList\"]/a[2] \n",
    "# 3p, //*[@id=\"pageList\"]/a[3]\n",
    "# 5p, //*[@id=\"pageList\"]/a[5]\n",
    "\n",
    "# ip, //*[@id=\"pageList\"]/a[i]\n",
    "\n",
    "\n",
    "# (2) 상세페이지로 이동해서 초록*키워드 데이터를 가져오는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e1659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "data_list = []\n",
    "for i in range(2,5):\n",
    "    time.sleep(5)\n",
    "    datas = browser.find_elements(By.CLASS_NAME, 'thesis')\n",
    "\n",
    "    for data in datas:\n",
    "        title = data.find_element(By.CLASS_NAME, 'thesis__tit').text\n",
    "        author = data.find_element(By.CLASS_NAME, 'thesis__item').text\n",
    "        count = data.find_element(By.CLASS_NAME, 'thesis__useCount').text[4:]\n",
    "        link = data.find_element(By.CLASS_NAME, 'thesis__link').get_attribute('href')\n",
    "\n",
    "        print(title, author, count, link)\n",
    "        \n",
    "        data = {\n",
    "            \"제목\" : title,\n",
    "            \"저자\" : author,\n",
    "            \"인용수\" : count,\n",
    "            \"링크\" : link\n",
    "        }\n",
    "        \n",
    "        data_list.append(data)\n",
    "\n",
    "    print(f\"{i} 페이지 입니다.\")    \n",
    "    xpath = f'//*[@id=\"pageList\"]/a[{}]'\n",
    "    browser.find_element(By.XPATH, xpath).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e2c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이건 웹에 관련된 사항일 것 같긴한데, \n",
    "# 저런식으로 창의 크기를 줄이는 것에 따라 내부 요소가 바뀌는 경우엔 \n",
    "# 보통 어떤식으로 안정적이게 처리(?) 하나요??\n",
    "browser.set_window_size(2048, 1024)# 픽셀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8044ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상세 페이지 뜯어보기\n",
    "# 1페이지에 나와있는 논문들의 초록*키워드 데이터를 가져오고 싶어요.\n",
    "\n",
    "# 1페이지 상세 페이지 링크를 수집\n",
    "links = browser.find_elements(By.CLASS_NAME, 'thesis__link')\n",
    "\n",
    "link_list = []\n",
    "for element in links:\n",
    "    link = element.get_attribute('href')\n",
    "    link_list.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ac288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for link in link_list:\n",
    "    time.sleep(3)\n",
    "    browser.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f088382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 안녕하세요 강사님!\n",
    "\n",
    "# https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11522387\n",
    "# 케이스처럼 초록, 키워드가 없는 경우 NoSuchElementException 에러가 발생하는데요.\n",
    "# 이럴 때는 검색해보니 try, except로 처리하라고 되어있는데 해결방법이 추가로 또 있나요..? \n",
    "# 코드가 길어지는 것 같아서 find_element 내에서 자체적으로 뭔가 처리하는 방법이 있나해서요.\n",
    "\n",
    "url = 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11522387'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    content = browser.find_element(By.CLASS_NAME, 'abstractTxt').text    \n",
    "except:\n",
    "    print(\"오류 발생\")\n",
    "    content = \"비어있음.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b906fd0",
   "metadata": {},
   "source": [
    "### SRT 예매 프로그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80085a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a844459",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://etk.srail.kr/cmc/01/selectLoginForm.do?pageId=TK0701000000'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e526e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 휴대전화 번호를 클릭 후, 휴대폰 번호 및 패스워드 입력 후 로그인 구현\n",
    "\n",
    "# AI Engineer의 수명은 !?\n",
    "# 머신러닝 엔지니어 -> 엄청난 사건이 벌어집니다. 나락가는 어떤 일이...\n",
    "# 알파고 = \"DeepLearning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c583a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element(By.ID, 'srchDvCd3').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61acf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element(By.ID, 'srchDvNm03').click()\n",
    "browser.find_element(By.ID, 'srchDvNm03').send_keys('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e43f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element(By.ID, 'hmpgPwdCphd03').click()\n",
    "browser.find_element(By.ID, 'hmpgPwdCphd03').send_keys('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b300c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인 버튼 클릭\n",
    "browser.find_element(By.XPATH, '//*[@id=\"login-form\"]/fieldset/div[1]/div[1]/div[4]/div/div[2]/input').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://etk.srail.kr/hpg/hra/01/selectScheduleList.do?pageId=TK0101010000'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element(By.XPATH, '//*[@id=\"search_top_tag\"]/input').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db414a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = browser.find_element(By.XPATH, '//*[@id=\"result-form\"]/fieldset/div[6]/table/tbody/tr[1]/td[6]/a').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "for i in range(10):\n",
    "    word = browser.find_element(By.XPATH, '//*[@id=\"result-form\"]/fieldset/div[6]/table/tbody/tr[1]/td[6]/a').text\n",
    "    print(word)\n",
    "    \n",
    "    if word == \"매진\":        \n",
    "        browser.refresh() # 새로고침\n",
    "        time.sleep(1)        \n",
    "    else:\n",
    "        browser.find_element(By.XPATH, '//*[@id=\"result-form\"]/fieldset/div[6]/table/tbody/tr[1]/td[6]/a').click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd61d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아까 DBpia 사이트 같은 논문 사이트에서 \n",
    "# 논문 자료들(pdf)을 자동으로 다운 받아서 저장 시킬 수 있는 방법도 있나요..?\n",
    "\n",
    "\n",
    "#browser.find_element(By.XPATH, '//*[@id=\"search_top_tag\"]/input').click()  \n",
    "#여기서 코드에 들어가는 xpath 값 어떻게 복사했는지 다시 알려주실수 있나요?\n",
    "\n",
    "# 혹시 강사님께서는 SRT 예매 프로그램을 영업직 분들께 전달하실때 어떤식으로 전달해주셨나요? \n",
    "# 프로그램화해서 전달해주셨을까요??\n",
    "\n",
    "# 파이썬 파일 전달해서 -> 영업직 직군분이 파이썬 다운로드 받고... ? ->?\n",
    "# pyinstaller\n",
    "# 간단한 홈페이지 만들어서 -> 휴대전화 번호 입력, 패스워드를 입력하면 -> 내컴퓨터에서 돌린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91628ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수업이랑 좀 상관없는 질문일수도 있는데, \n",
    "# 혹시 REST API랑 Websocket API 사용사례의 예를 설명해주실수 있을까요?\n",
    "\n",
    "# Websocket API\n",
    "# - 배달의민족 쓰시죠? 라이더 실시간으로 이동하잖아요. 그때 웹소켓을 사용합니다.\n",
    "# - 카카오톡. 제가 보면 숫자가 줄어들죠? 실시간으로.\n",
    "# - 왜 웹소켓인가? 데이터를 계속 주고 받고 주고 받고.\n",
    "\n",
    "# REST API\n",
    "# - 직접 만들어보자. flask -> 3분.\n",
    "# Django -> DB가 필요해서 15~20분?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37995dff",
   "metadata": {},
   "source": [
    "### 슬랙 DATA PIPELINE 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610da562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # 요청을 날릴 때 사용하는 라이브러리\n",
    "import json\n",
    "\n",
    "# curl \n",
    "# -X POST (GET) -> REST API\n",
    "# -H 'Content-type: application/json' \n",
    "# --data '{\"text\":\"Hello, World!\"}'  # params\n",
    "# https://hooks.slack.com/services/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\n",
    "\n",
    "slack_url = 'https://hooks.slack.com/services/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'\n",
    "\n",
    "msg = \"\"\"\n",
    "안녕하세요 오늘은 파이썬의 크롤링을 배웠습니다.\n",
    "여기에 나중에 뉴스를 공유를 할 예정입니다.\n",
    "\"\"\"\n",
    "\n",
    "# {\"text\":msg} -> json 같아보여요. 파이썬의 딕셔너리\n",
    "requests.post(slack_url, \n",
    "              data=json.dumps({\"text\":msg}),\n",
    "              headers={\"Content-Type\" : \"application/json\"}\n",
    "             )\n",
    "\n",
    "# 당신은 인공지능에 관한 정보를 어떻게 수집하고 있나요? 어떤 사이트를 주로 보시나요?\n",
    "# 요즘에 보신 것 중에 인상 깊었던 것 얘기 좀 해주세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6f2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post 요청을 설명한 곳에서\n",
    "# --data와\n",
    "# --data-urlencode의 차이를 설명해주시면 감사하겠습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a365c",
   "metadata": {},
   "source": [
    "### YES24 베스트셀러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d53219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 웹 페이지 열기\n",
    "url = \"https://www.yes24.com/Product/category/bestseller?CategoryNumber=001&sumgb=06\"\n",
    "driver.get(url)\n",
    "\n",
    "# 웹 페이지가 로딩될 때까지 대기 (선택 사항)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# 책 정보를 담을 리스트 초기화\n",
    "books = []\n",
    "\n",
    "# 책 정보 수집\n",
    "book_elements = driver.find_elements(By.CLASS_NAME, 'item_info')\n",
    "for element in book_elements:\n",
    "    title = element.find_element(By.CLASS_NAME, 'gd_name').text    \n",
    "    author = element.find_element(By.CLASS_NAME, 'authPub').text\n",
    "    sales_rank = element.find_element(By.CLASS_NAME, 'saleNum').text\n",
    "\n",
    "    book_info = {\n",
    "        '제목': title,\n",
    "        '저자': author,\n",
    "        '판매지수': sales_rank\n",
    "    }\n",
    "    books.append(book_info)\n",
    "\n",
    "books\n",
    "# # 웹 드라이버 종료\n",
    "# driver.quit()\n",
    "\n",
    "# # 데이터프레임 생성\n",
    "# df = pd.DataFrame(books)\n",
    "\n",
    "# # 데이터프레임을 엑셀 파일로 저장\n",
    "# df.to_excel('yes24_bestsellers.xlsx', index=False, encoding='utf-8')\n",
    "\n",
    "# print(\"데이터 수집 및 엑셀 파일 저장이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저걸 매일 수동으로 실행시켜야 하나요? \n",
    "# 예를들어 아침 7시마다 실행되게 할 수 있나요?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss",
   "language": "python",
   "name": "ss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
